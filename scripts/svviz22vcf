#!/usr/bin/env python3
import argparse, logging, os, re, sys
from typing import List
import numpy as np
import pandas as pd
import vcf

COLUMN_HEADERS = ["CHROM","POS","ID","REF","ALT","QUAL","FILTER","INFO","FORMAT"]

# Format fields
FORMAT = "GT:GQ:GL:AD"


def makeArgParser():
    """
    Returns an argument parser parser with the command line arguments
    """
    parser = argparse.ArgumentParser(
        description="Concatenate .tsv reports generated by svviz2 into a single .vcf file",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument(
        "-i", "--input", type=str, help="Path to input vcf file", required=True
    )
    parser.add_argument(
        "-r",
        "--reports",
        type=str,
        help="Path to the folder of svviz2 reports",
        required=True,
    )
    parser.add_argument(
        "-o", "--output", type=str, help="Path to output VCF file", required=True
    )
    parser.add_argument(
        "-s", "--samples", type=str, help="Sample names", action="append", required=True
    )
    parser.add_argument(
        "--model",
        type=str,
        help="svviz2 model for GT, ... One of 'count','weighted','mapq'",
        default="count",
    )
    return parser


def report_name(record: vcf.model._Record) -> List[str]:
    """Generate report names as created by svvi2"""
    # Match the scheme used in svviz2
    # https://github.com/nspies/svviz2/blob/44f7bfc75bf84c1db4563d9fd30bf20967d1c825/src/svviz2/app/variants.py#L259
    id = (record.ID or f"{record.CHROM}_{record.POS}_{record.sv_end}").replace(":","_").replace(";","")
    kind = (record.INFO.get("SVTYPE", None) or record.var_subtype)[:3].lower()
    end = record.sv_end or (record.POS + len(record.REF) - 1)
    return [
        f"{id}.{kind}_{record.CHROM}_{record.POS-1}",
        f"{id}.{kind}_{record.CHROM}_{record.POS}",
        f"{id}.SequenceDefinedVariant.{record.CHROM}_{record.POS-1}-{end-1}",
    ]


def get_value(grouping, key) -> str:
    """Get svviz2 report value for allele and key
    
    Args:
        grouping (tuple(allele, key)): Pandas group
        key (tuple(allele, key)): Tuple of svviz2 allele and key
    
    Returns:
        str: Value
    """
    return grouping.get_group(key).iat[0, 3]


def get_numeric_list(grouping, key, digits=0) -> List[str]:
    """Get svviz2 report numeric value for allele and key
    
    Args:
        grouping (tuple(allele, key)): Pandas group
        key (tuple(allele, key)): Tuple of svviz2 allele and key
        digits (int, optional): 0 for integer. Defaults to 0.
    
    Returns:
        List[str]: List of rounded strings
    """
    value = get_value(grouping, key)
    return map(lambda n: str(round(float(n), digits)), value.strip("[]").split())


def get_GQ(grouping, key) -> float:
    """Compute GQ value from from svviz2 GL_* value"""
    values = [-10.0*float(v) for v in get_value(grouping, key).strip("[]").split()]
    values = sorted(values)
    return values[1] - values[0]


def construct_call(table, model="count") -> str:
    """Return VCF sample entry from svviz2 sample dataframe"""
    alleles = table.groupby(["allele", "key"])
    return "{gt}:{gq:.0f}:{gl}:{ref},{alt}".format(
        gt=get_value(alleles, ("all", f"GT_{model}")),
        gq=min(get_GQ(alleles, ("all", f"GL_{model}")), 99),
        gl=",".join(get_numeric_list(alleles, ("all", f"GL_{model}"), 2)),
        ref=get_value(alleles, ("ref", "count")),
        alt=get_value(alleles, ("alt", "count")),
    )


def main(args):

    vcf_reader = vcf.Reader(filename=args.input)  # Original VCF file

    # Add new fields to the header
    vcf_reader.formats["GT"] = vcf.parser._Format(
        "GT", 1, "String", f"Genotype (from GT_{args.model})"
    )
    vcf_reader.formats["GQ"] = vcf.parser._Format(
        "GQ", 1, "Float", f"Genotype quality (from GL_{args.model})"
    )
    vcf_reader.formats["GL"] = vcf.parser._Format(
        "GL", "G", "Float", f"Genotype likelihoods (from GL_{args.model})"
    )
    vcf_reader.formats["AD"] = vcf.parser._Format(
        "AD", "R", "Integer", "Count for each allele (from count)"
    )

    if len(vcf_reader._column_headers) < 9:
        # If original VCF is sites only...
        vcf_reader._column_headers = COLUMN_HEADERS
    vcf_reader.samples = args.samples  # Overwrite sample names for header

    with open(args.output, "w") as output_file:
        vcf_writer = vcf.Writer(output_file, vcf_reader, lineterminator="")

        for record in vcf_reader:
            # Construct report file name
            for report_prefix in report_name(record):
                report_path = os.path.join(args.reports, report_prefix + ".report.tsv")
                if os.path.exists(report_path):
                    break
            else:
                logging.warn(
                    "Can't find report files for prefixes %s. Skipping variant.",
                    ", ".join(report_name(record)),
                )
                continue

            # Load report, fill empty allele entries with "all"
            report = pd.read_csv(report_path, sep="\t")
            report.fillna({"allele": "all"}, inplace=True)

            # Overwrite FORMAT and samples
            record.FORMAT = None
            record.samples = []  

            # Write sites-only
            vcf_writer.write_record(record)

            # Sample entries
            output_file.write(f"\t{FORMAT}")

            samples = {}
            for sample, group in report.groupby("sample"):
                samples[sample] = construct_call(group, args.model)
            for sample in args.samples:
                # Write samples in header order (or '.' if missing)
                output_file.write(f"\t{samples.get(sample, '.')}")

            output_file.write("\n")  # Finish off the line


if __name__ == "__main__":
    parser = makeArgParser()
    args = parser.parse_args()
    main(args)

